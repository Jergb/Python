{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a importar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HUMEDAD DE LA TIERRA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>INTENSIDAD LUMÍNICA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-05 14:41:00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5841.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-05 14:42:00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5847.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-05 14:43:00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5841.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-05 14:44:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5841.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-05 14:45:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5841.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  HUMEDAD DE LA TIERRA  HUMEDAD RELATIVA  \\\n",
       "0  2018-06-05 14:41:00                  6.11              16.0   \n",
       "1  2018-06-05 14:42:00                  6.11              16.0   \n",
       "2  2018-06-05 14:43:00                  6.11              16.0   \n",
       "3  2018-06-05 14:44:00                  5.95              16.0   \n",
       "4  2018-06-05 14:45:00                  5.95              16.0   \n",
       "\n",
       "   INTENSIDAD LUMÍNICA  TEMPERATURA  \n",
       "0               5841.0         34.0  \n",
       "1               5847.0         34.0  \n",
       "2               5841.0         34.0  \n",
       "3               5841.0         34.0  \n",
       "4               5841.0         34.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#data = pd.ExcelFile('stockindexes.xls')\n",
    "data = pd.read_csv('nodo2_periodo3.csv')\n",
    "data.head()\n",
    "#data.sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftse_data = data.parse('FTSE100')\n",
    "dj_data = data.parse('Dow Jones Industrial')\n",
    "display(ftse_data.head())\n",
    "display(dj_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftse100 = ftse_data.iloc[4:1357 ,1]\n",
    "dj = dj_data.iloc[4:1357 ,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(ftse100.head())\n",
    "display(ftse100.tail())\n",
    "display(dj.head())\n",
    "display(dj.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamo a acrear las variables objetivo: targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURA  HUMEDAD RELATIVA\n",
       "0         34.0              16.0\n",
       "1         34.0              16.0\n",
       "2         34.0              16.0\n",
       "3         34.0              16.0\n",
       "4         34.0              16.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = data[['TEMPERATURA', 'HUMEDAD RELATIVA']]\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yt = yt.reset_index ( drop = True )\n",
    "yt.columns = ['ftse100','dj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURA  HUMEDAD RELATIVA\n",
       "0         34.0              16.0\n",
       "1         34.0              16.0\n",
       "2         34.0              16.0\n",
       "3         34.0              16.0\n",
       "4         34.0              16.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamo a pasar una ventana deslizante que calcula la desviación estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = yt.pct_change(1)\n",
    "win =30\n",
    "volt_t = yt.rolling(window = win , center = True ).std ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a3b3ec4a90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(volt_t.iloc[:,0])\n",
    "plt.figure()\n",
    "plt.plot(volt_t.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agrega características \"HEchas a mano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jergb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Jergb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\Jergb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD RELATIVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TEMPERATURA  HUMEDAD RELATIVA  TEMPERATURA  HUMEDAD RELATIVA  TEMPERATURA  \\\n",
       "0           NaN               NaN          NaN               NaN          NaN   \n",
       "1           NaN               NaN          NaN               NaN          NaN   \n",
       "2           NaN               NaN          NaN               NaN          NaN   \n",
       "3           NaN               NaN          NaN               NaN          NaN   \n",
       "4           NaN               NaN          NaN               NaN          NaN   \n",
       "5           NaN               NaN          NaN               NaN          NaN   \n",
       "6           NaN               NaN          NaN               NaN          NaN   \n",
       "7           NaN               NaN          NaN               NaN          NaN   \n",
       "8           NaN               NaN          NaN               NaN          NaN   \n",
       "9           NaN               NaN          NaN               NaN          NaN   \n",
       "10          NaN               NaN          NaN               NaN          NaN   \n",
       "11          NaN               NaN          NaN               NaN          NaN   \n",
       "12          NaN               NaN          NaN               NaN          NaN   \n",
       "13          NaN               NaN          NaN               NaN          NaN   \n",
       "14          NaN               NaN          NaN               NaN          NaN   \n",
       "15          NaN               NaN          NaN               NaN          NaN   \n",
       "16          0.0               0.0          NaN               NaN          NaN   \n",
       "17          0.0               0.0          NaN               NaN          NaN   \n",
       "18          0.0               0.0          NaN               NaN          NaN   \n",
       "19          0.0               0.0          NaN               NaN          NaN   \n",
       "\n",
       "    HUMEDAD RELATIVA  TEMPERATURA  HUMEDAD RELATIVA  TEMPERATURA  \\\n",
       "0                NaN          NaN               NaN          NaN   \n",
       "1                NaN          NaN               NaN          NaN   \n",
       "2                NaN          NaN               NaN          NaN   \n",
       "3                NaN          NaN               NaN          NaN   \n",
       "4                NaN          NaN               NaN          NaN   \n",
       "5                NaN          NaN               NaN          NaN   \n",
       "6                NaN          NaN               NaN          NaN   \n",
       "7                NaN          NaN               NaN          NaN   \n",
       "8                NaN          NaN               NaN          NaN   \n",
       "9                NaN          NaN               NaN          NaN   \n",
       "10               NaN          NaN               NaN          NaN   \n",
       "11               NaN          NaN               NaN          NaN   \n",
       "12               NaN          NaN               NaN          NaN   \n",
       "13               NaN          NaN               NaN          NaN   \n",
       "14               NaN          NaN               NaN          NaN   \n",
       "15               NaN          NaN               NaN          NaN   \n",
       "16               NaN          NaN               NaN          NaN   \n",
       "17               NaN          NaN               NaN          NaN   \n",
       "18               NaN          NaN               NaN          NaN   \n",
       "19               NaN          NaN               NaN          NaN   \n",
       "\n",
       "    HUMEDAD RELATIVA  TEMPERATURA  HUMEDAD RELATIVA  \n",
       "0                NaN          NaN               NaN  \n",
       "1                NaN          NaN               NaN  \n",
       "2                NaN          NaN               NaN  \n",
       "3                NaN          NaN               NaN  \n",
       "4                NaN          NaN               NaN  \n",
       "5                NaN          NaN               NaN  \n",
       "6                NaN          NaN               NaN  \n",
       "7                NaN          NaN               NaN  \n",
       "8                NaN          NaN               NaN  \n",
       "9                NaN          NaN               NaN  \n",
       "10               NaN          NaN               NaN  \n",
       "11               NaN          NaN               NaN  \n",
       "12               NaN          NaN               NaN  \n",
       "13               NaN          NaN               NaN  \n",
       "14               NaN          NaN               NaN  \n",
       "15               NaN          NaN               NaN  \n",
       "16               NaN          NaN               NaN  \n",
       "17               NaN          NaN               NaN  \n",
       "18               NaN          NaN               NaN  \n",
       "19               NaN          NaN               NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=np.log((volt_t.shift(1)/volt_t.shift(2))*volt_t.shift(1))\n",
    "x2=np.log((volt_t.shift(1)/volt_t.shift(3))*volt_t.shift(1))\n",
    "x3=np.log((volt_t.shift(1)/volt_t.shift(4))*volt_t.shift(1))\n",
    "x4=np.log((volt_t.shift(1)/volt_t.shift(5))*volt_t.shift(1))\n",
    "x5=np.log((volt_t.shift(1)/volt_t.shift(6))*volt_t.shift(1))\n",
    "data = pd.concat([volt_t,x1,x2,x3,x4,x5],axis=1)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftse_t</th>\n",
       "      <th>dj_t</th>\n",
       "      <th>ftse_t-1</th>\n",
       "      <th>dj_t-1</th>\n",
       "      <th>ftse_t-2</th>\n",
       "      <th>dj_t-2</th>\n",
       "      <th>ftse_t-3</th>\n",
       "      <th>dj_t-3</th>\n",
       "      <th>ftse_t-4</th>\n",
       "      <th>dj_t-4</th>\n",
       "      <th>ftse_t-5</th>\n",
       "      <th>dj_t-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>-4.464436</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>-4.656364</td>\n",
       "      <td>-4.473187</td>\n",
       "      <td>-4.464436</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>-4.656364</td>\n",
       "      <td>-4.473187</td>\n",
       "      <td>-4.656364</td>\n",
       "      <td>-4.473187</td>\n",
       "      <td>-4.464436</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "      <td>-4.085770</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.184160</td>\n",
       "      <td>inf</td>\n",
       "      <td>-3.805494</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.020463</td>\n",
       "      <td>-4.516226</td>\n",
       "      <td>-4.076388</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.376088</td>\n",
       "      <td>-3.679588</td>\n",
       "      <td>-4.184160</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ftse_t      dj_t  ftse_t-1    dj_t-1  ftse_t-2    dj_t-2  ftse_t-3  \\\n",
       "47  0.009501  0.011411 -4.464436       inf -4.085770       inf -4.085770   \n",
       "48  0.009501  0.011411 -4.656364 -4.473187 -4.464436       inf -4.085770   \n",
       "49  0.010930  0.016969 -4.656364 -4.473187 -4.656364 -4.473187 -4.464436   \n",
       "50  0.010930  0.016969 -4.376088 -3.679588 -4.376088 -3.679588 -4.376088   \n",
       "51  0.012173  0.020463 -4.516226 -4.076388 -4.376088 -3.679588 -4.376088   \n",
       "\n",
       "      dj_t-3  ftse_t-4    dj_t-4  ftse_t-5  dj_t-5  \n",
       "47       inf -4.085770       inf -4.085770     inf  \n",
       "48       inf -4.085770       inf -4.085770     inf  \n",
       "49       inf -4.085770       inf -4.085770     inf  \n",
       "50 -3.679588 -4.184160       inf -3.805494     inf  \n",
       "51 -3.679588 -4.376088 -3.679588 -4.184160     inf  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['ftse_t','dj_t','ftse_t-1','dj_t-1','ftse_t-2','dj_t-2','ftse_t-3','dj_t-3',\n",
    "                'ftse_t-4','dj_t-4','ftse_t-5','dj_t-5']\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_y =['ftse_t', 'dj_t']\n",
    "y = data[cols_y]\n",
    "cols =['ftse_t-1','dj_t-1','ftse_t-2','dj_t-2','ftse_t-3','dj_t-3','ftse_t-4','dj_t-4','ftse_t-5','dj_t-5']\n",
    "x = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2943, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2943, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jergb\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7a80080e4af0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_attrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mnum_response\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[1;32m--> 334\u001b[1;33m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "num_attrib=10\n",
    "scaler_x=preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "x=np.array(x).reshape((len(x),num_attrib))\n",
    "x=scaler_x.fit_transform(x)\n",
    "num_response=2\n",
    "scaler_y=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "y=np.array(y).reshape((len(y),num_response))\n",
    "y=scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end=1131\n",
    "data_end=len(y)\n",
    "x_train=x[0:train_end,]\n",
    "x_test=x[train_end+1:data_end,]\n",
    "y_train=y[0:train_end]\n",
    "y_test=y[train_end+1:data_end]\n",
    "x_train=np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapeofx_trainis',x_train.shape)\n",
    "print('Shapeofx_testis',x_test.shape)\n",
    "print('Shape of y_train is ', y_train.shape)\n",
    "print('Shape of y_test is ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2016\n",
    "num_epochs=20\n",
    "np.random.seed(seed)\n",
    "fit1=Sequential()\n",
    "fit1.add(SimpleRNN(units=10,activation='sigmoid',input_shape=(1,num_attrib)))\n",
    "fit1.add(Dense(units=num_response,activation='linear'))\n",
    "sgd=SGD(lr=0.01,momentum=0.90,nesterov=True)\n",
    "fit1.compile(loss='mean_squared_error',optimizer=sgd)\n",
    "history = fit1.fit(x_train,y_train,batch_size=1, verbose=0,epochs=num_epochs)\n",
    "# Thetrainandtestsetperformanceare:\n",
    "score_train=fit1.evaluate(x_train,y_train,batch_size=1)\n",
    "score_test=fit1.evaluate(x_test,y_test,batch_size=1)\n",
    "\n",
    "print('in train MSE=',round(score_train,5))\n",
    "print('in test MSE=',round(score_test,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=fit1.predict(x_test)#0.00114387514427\n",
    "pred1=scaler_y.inverse_transform(np.array(pred1).reshape((len(pred1),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entreno=scaler_y.inverse_transform(np.array(y_test).reshape((len(y_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred1[:,0])\n",
    "plt.plot(entreno[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred1[:,1])\n",
    "plt.plot(entreno[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pacf = pacf(yt, nlags=30, method='ols')\n",
    "plt.plot(x_pacf)\n",
    "plt.plot(len(x_pacf)*[0],'--')\n",
    "plt.title(' Partial autocorrelation function for Monthly Sunspots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model we use 5 time lags of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_1=yt.shift(1)\n",
    "yt_2=yt.shift(2)\n",
    "yt_3=yt.shift(3)\n",
    "yt_4=yt.shift(4)\n",
    "yt_5=yt.shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([yt,yt_1,yt_2,yt_3,yt_4,yt_5],axis =1)\n",
    "data.columns = ['yt', 'yt_1', 'yt_2', 'yt_3', 'yt_4', 'yt_5']\n",
    "display(data.head(6))\n",
    "display(data.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "y = data['yt']\n",
    "cols = ['yt_1','yt_2','yt_3','yt_4','yt_5']\n",
    "print(cols)\n",
    "x = data[cols]\n",
    "display(y.head())\n",
    "display(y.tail())\n",
    "display(x.head())\n",
    "display(x.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# scaler para x\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 columnas\n",
    "x = np.array(x).reshape((len(x),5))\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler para y\n",
    "scaler_y = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "y = np.array(y).reshape((len(y),1))\n",
    "y = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = int(len(y)*.8)\n",
    "x_train = x[0:train_end,]\n",
    "x_test = x[train_end+1:len(y),]\n",
    "y_train = y[0:train_end]\n",
    "y_test = y[train_end+1:len(y)]\n",
    "x_train = x_train.reshape(x_train.shape+(1,))\n",
    "x_test = x_test.reshape(x_test.shape+(1,))\n",
    "\n",
    "print('Shape of x_train is ', x_train.shape)\n",
    "print('Shape of x_test is ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa el modelo secuencial, permite apilar capas de manera lineal\n",
    "from keras.models import Sequential\n",
    "# importa la capa densa, esta es una capa de red neuronal completamente conectada regular\n",
    "# con una función lineal de activación\n",
    "from keras.layers import Dense, Activation\n",
    "# Optimizador de descenso de gradiente estocástico\n",
    "from keras.layers.recurrent import LSTM\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una semilla para tener resultados repetibles\n",
    "seed = 2016\n",
    "np.random.seed(seed)\n",
    "# Define el modelo secuencial\n",
    "fit1 = Sequential()\n",
    "# Agrega una capa LSTM con cuatro neuronas, activación tanh, activación interoir hard_sgimoitde\n",
    "# y forma de entrada (5,1)\n",
    "fit1.add(LSTM(units=4,activation='tanh',\n",
    "              recurrent_activation='hard_sigmoid',\n",
    "              input_shape=(5,1)))\n",
    "#Agrega una capa densa con una slida y activación lineal\n",
    "fit1.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una semilla para tener resultados repetibles\n",
    "seed = 2016\n",
    "np.random.seed(seed)\n",
    "# Define el modelo secuencial\n",
    "fit2 = Sequential()\n",
    "# Agrega una capa LSTM con cuatro neuronas, activación tanh, activación interoir hard_sgimoitde\n",
    "# y forma de entrada (5,1)\n",
    "fit2.add(LSTM(units=4,activation='tanh',\n",
    "              recurrent_activation='hard_sigmoid',\n",
    "              input_shape=(5,1)))\n",
    "#Agrega una capa densa con una slida y activación lineal\n",
    "fit2.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "#Ajustar el modelo\n",
    "history1 = fit1.fit(x_train, y_train, batch_size = 1, epochs=10, verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "#Ajustar el modelo\n",
    "history2 = fit2.fit(x_train, y_train, batch_size = 1, epochs=10, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed =2016\n",
    "#np.random.seed(seed)\n",
    "fit3 = Sequential ()\n",
    "# The batch_input_shape takes the batch size (1 in our example), number of attributes \n",
    "#(5 time lagged variables) and number of time steps (1 month forecast).\n",
    "fit3.add(LSTM(units=4,stateful=True,batch_input_shape=(1,5,1),activation='tanh',\n",
    "              recurrent_activation ='hard_sigmoid'))\n",
    "fit3.add(Dense(units=1,activation='linear'))\n",
    "fit3.compile(loss='mean_squared_error',optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed =2016\n",
    "#np.random.seed(seed)\n",
    "fit4 = Sequential ()\n",
    "# The batch_input_shape takes the batch size (1 in our example), number of attributes \n",
    "#(5 time lagged variables) and number of time steps (1 month forecast).\n",
    "fit4.add(LSTM(units=4,stateful=True,batch_input_shape=(1,5,1),activation='tanh',\n",
    "              recurrent_activation ='hard_sigmoid'))\n",
    "fit4.add(Dense(units=1,activation='linear'))\n",
    "fit4.compile(loss='mean_squared_error',optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_point =len(x_train)\n",
    "start_point =end_point - 50\n",
    "\n",
    "#The model has to be trained one epoch at a time with the\n",
    "#state reset after each epoch\n",
    "\n",
    "history3=[]\n",
    "for i in range(len(x_train[start_point:end_point])):\n",
    "    history3.append(fit3.fit(x_train[start_point:end_point],y_train[start_point:end_point],epochs=1,\n",
    "             batch_size=1,verbose=0,shuffle=False))\n",
    "    fit3.reset_states()\n",
    "    \n",
    "history4=[]\n",
    "for i in range(len(x_train[start_point:end_point])):\n",
    "    history4.append(fit4.fit(x_train[start_point:end_point],y_train[start_point:end_point],epochs=1,\n",
    "             batch_size=1,verbose=0,shuffle=True))\n",
    "    fit4.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import GRU\n",
    "\n",
    "fit5 = Sequential ()\n",
    "#return_sequeinces=False para trabajar con una sola objetivo\n",
    "#Para trabajar con varios objetivos se deja en True\n",
    "fit5.add(GRU(units=4,return_sequences= False,activation='tanh',\n",
    "             recurrent_activation='hard_sigmoid',input_shape=(5,1)))\n",
    "fit5.add(Dense(units=1,activation='linear'))\n",
    "fit5.compile(loss='mean_squared_error',optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = fit5.fit(x_train,y_train,batch_size=1,verbose=0,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the\n",
    "model will forecast the next month based on the last 500 rolling\n",
    "months of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the batch size, the more memory you\n",
    "will need to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fit1.summary())\n",
    "display(fit2.summary())\n",
    "display(fit3.summary())\n",
    "display(fit4.summary())\n",
    "display(fit5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo\n",
    "Train and Test MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train1 = fit1.evaluate(x_train, y_train, batch_size=1)\n",
    "score_test1 = fit1.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('in train2 MSE = ', round(score_train1,4))\n",
    "print('in test2 MSE = ', round( score_test1 ,4))\n",
    "\n",
    "score_train2 = fit2.evaluate(x_train, y_train, batch_size=1)\n",
    "score_test2 = fit2.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('in train2 MSE = ', round(score_train2,4))\n",
    "print('in test2 MSE = ', round( score_test2 ,4))\n",
    "\n",
    "score_train3 = fit3.evaluate(x_train, y_train, batch_size=1)\n",
    "score_test3 = fit3.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('in train3 MSE = ', round(score_train3,4))\n",
    "print('in test3 MSE = ', round( score_test3,4))\n",
    "\n",
    "score_train4 = fit4.evaluate(x_train, y_train, batch_size=1)\n",
    "score_test4 = fit4.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('in train4 MSE = ', round(score_train4,4))\n",
    "print('in test4 MSE = ', round( score_test4,4))\n",
    "\n",
    "score_train5 = fit5.evaluate(x_train, y_train, batch_size=1)\n",
    "score_test5 = fit5.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('in train5 MSE = ', round(score_train5,4))\n",
    "print('in test5 MSE = ', round( score_test5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to convert the predictions back to their original scale,\n",
    "so we can view them individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "entreno = scaler_y.inverse_transform(np.array(y_test).reshape((len(y_test),1)))\n",
    "plt.figure(figsize=[16,8])\n",
    "plt.plot(np.rint(entreno),label='set de prueba',linewidth=2)\n",
    "\n",
    "pred1 = fit1.predict(x_test)\n",
    "pred1 = scaler_y.inverse_transform(np.array(pred1).reshape((len(pred1),1)))\n",
    "\n",
    "# Difrerenca entre rms y rmse\n",
    "# Se calcula el error rms\n",
    "\n",
    "p1 = math.sqrt(mean_squared_error(pred1, entreno))\n",
    "#RSME idntefica los grandes errores\n",
    "#RSM identifica la variación de disftribución de frecuencias\n",
    "#https://translate.googleusercontent.com/translate_c?depth=1&hl=es&prev=search&rurl=translate.google.com&sl=en&sp=nmt4&u=https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d&xid=17259,15700023,15700186,15700191,15700248&usg=ALkJrhipwo7TP2PruqpEsfcKMCIVIjSq4Q\n",
    "\n",
    "plt.plot(np.rint(pred1),label='predicción sin shuffle (%.2f)'%p1)\n",
    "\n",
    "pred2 = fit2.predict(x_test)\n",
    "pred2 = scaler_y.inverse_transform(np.array(pred2).reshape((len(pred2),1)))\n",
    "\n",
    "p2 = math.sqrt(mean_squared_error(pred2, entreno))\n",
    "\n",
    "plt.plot(np.rint(pred2),label='predicción con suffle (%.2f)'%p2)\n",
    "\n",
    "pred3 = fit3.predict(x_test,batch_size=1)\n",
    "pred3 = scaler_y.inverse_transform(np.array(pred3).reshape((len(pred3),1)))\n",
    "\n",
    "p3 = math.sqrt(mean_squared_error(pred3, entreno))\n",
    "\n",
    "plt.plot(np.rint(pred3),label='predicción con estado sin suffle (%.2f)'%p3)\n",
    "\n",
    "pred4 = fit4.predict(x_test,batch_size=1)\n",
    "pred4 = scaler_y.inverse_transform(np.array(pred4).reshape((len(pred4),1)))\n",
    "\n",
    "p4 = math.sqrt(mean_squared_error(pred4, entreno))\n",
    "\n",
    "plt.plot(np.rint(pred4),label='predicción con estado con suffle (%.2f)'%p4)\n",
    "\n",
    "pred5 = fit5.predict(x_test,batch_size=1)\n",
    "pred5 = scaler_y.inverse_transform(np.array(pred5).reshape((len(pred5),1)))\n",
    "\n",
    "p5 = math.sqrt(mean_squared_error(pred5, entreno))\n",
    "\n",
    "plt.plot(np.rint(pred5),label='predicción con GRU (%.2f)'%p5)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.rint(pred1),np.rint(entreno),alpha=.1,label='predicción sin suffle')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.scatter(np.rint(pred2),np.rint(entreno),alpha=.1,label='predicción con suffle')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.scatter(np.rint(pred3),np.rint(entreno),alpha=.1,label='predicción con estado sin suffle')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.scatter(np.rint(pred4),np.rint(entreno),alpha=.1,label='predicción con estado con suffle')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.scatter(np.rint(pred5),np.rint(entreno),alpha=.1,label='predicción con GRU')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['loss'], 'r', label='pérdidas sin shuffle')\n",
    "plt.plot(history2.history['loss'], 'b', label='pérdidas con shuffle')\n",
    "plt.plot(history5.history['loss'], 'g', label='pérdidas con GRU')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "h3 = [x.history['loss'] for x in history3]\n",
    "plt.plot(h3, 'r', label='pérdidas con estado sin shuffle')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "h4 = [x.history['loss'] for x in history4]\n",
    "plt.plot(h4, 'b', label='pérdidas con estado con shuffle')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicciones del entrenamiento de cambio para plotear\n",
    "#trainPredictPlot = numpy.empty_like(data)\n",
    "\n",
    "\n",
    "\n",
    "y = scaler_y.inverse_transform(np.array(y))#.reshape((y,1)))\n",
    "y_train = scaler_y.inverse_transform(np.array(y_train))\n",
    "\n",
    "\n",
    "plt.figure(figsize=[16,8])\n",
    "xplot =x\n",
    "ventana = 5\n",
    "trainPredictPlot = np.empty_like(y_train)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[0:len(y_train), :] = y_train\n",
    "plt.plot(trainPredictPlot)\n",
    "\n",
    "vPredictPlot = np.empty_like(y)\n",
    "vPredictPlot[:, :] = np.nan\n",
    "vPredictPlot[len(y_train)+1:len(y), :] = np.rint(pred2)\n",
    "plt.plot(vPredictPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_end = int(len(y)*.8)  \n",
    "x_train = x[0:train_end,]  \n",
    "x_test = x[train_end+1:len(y),]  \n",
    "y_train = y[0:train_end]  \n",
    "y_test = y[train_end+1:len(y)]  \n",
    "x_train = x_train.reshape(x_train.shape+(1,))  \n",
    "x_test = x_test.reshape(x_test.shape+(1,))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
