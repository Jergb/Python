{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a importar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "temp = pd.read_csv('COE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>COE$</th>\n",
       "      <th>COE$_1</th>\n",
       "      <th>#Bids</th>\n",
       "      <th>Quota</th>\n",
       "      <th>Open?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1990-08-01</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>656</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990-09-01</td>\n",
       "      <td>11100.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>1462</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1990-10-01</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>11100.0</td>\n",
       "      <td>633</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1990-11-01</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>952</td>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1990-12-01</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>919</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        DATE     COE$   COE$_1  #Bids  Quota  Open?\n",
       "0           0  1990-08-01   7400.0   7750.0    656    472      0\n",
       "1           1  1990-09-01  11100.0   7400.0   1462    468      0\n",
       "2           2  1990-10-01   5002.0  11100.0    633    472      0\n",
       "3           3  1990-11-01   3170.0   5002.0    952    511      0\n",
       "4           4  1990-12-01   3410.0   3170.0    919    471      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COE$</th>\n",
       "      <th>COE$_1</th>\n",
       "      <th>#Bids</th>\n",
       "      <th>Quota</th>\n",
       "      <th>Open?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7400.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>656</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11100.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>1462</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5002.0</td>\n",
       "      <td>11100.0</td>\n",
       "      <td>633</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3170.0</td>\n",
       "      <td>5002.0</td>\n",
       "      <td>952</td>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3410.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>919</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COE$   COE$_1  #Bids  Quota  Open?\n",
       "0   7400.0   7750.0    656    472      0\n",
       "1  11100.0   7400.0   1462    468      0\n",
       "2   5002.0  11100.0    633    472      0\n",
       "3   3170.0   5002.0    952    511      0\n",
       "4   3410.0   3170.0    919    471      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = temp.drop(temp.columns[[0,1]],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COE$_1</th>\n",
       "      <th>#Bids</th>\n",
       "      <th>Quota</th>\n",
       "      <th>Open?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.955448</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>6.156979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.909235</td>\n",
       "      <td>7.287561</td>\n",
       "      <td>6.148468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.314700</td>\n",
       "      <td>6.450470</td>\n",
       "      <td>6.156979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.517593</td>\n",
       "      <td>6.858565</td>\n",
       "      <td>6.236370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.061487</td>\n",
       "      <td>6.823286</td>\n",
       "      <td>6.154858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COE$_1     #Bids     Quota  Open?\n",
       "0  8.955448  6.486161  6.156979      0\n",
       "1  8.909235  7.287561  6.148468      0\n",
       "2  9.314700  6.450470  6.156979      0\n",
       "3  8.517593  6.858565  6.236370      0\n",
       "4  8.061487  6.823286  6.154858      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data['COE$']\n",
    "x=data.drop(data.columns[[0,4]],axis=1)\n",
    "#Realiza la transformación logaritmica de x\n",
    "x=x.apply(np.log)\n",
    "x=pd.concat([x,data['Open?']],axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x).reshape((len(x),4))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "y = np.array(y).reshape((len(y),1))\n",
    "y = np.log(y)\n",
    "y = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Sets\n",
    "For this illustration, the train set contains around 95% of the\n",
    "observations, with the remaining allocated to the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero vamo a separar datos\n",
    " Crear los sets de entrenamiento  de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = len(x)-1\n",
    "learn_end = int(end*0.954)\n",
    "x_train = x[0:learn_end-1,]\n",
    "x_test = x[learn_end:end-1,]\n",
    "y_train = y[1:learn_end]\n",
    "y_test = y[learn_end+1:end]\n",
    "x_train = x_train.reshape(x_train.shape+(1,))\n",
    "x_test = x_test.reshape(x_test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train is  (250, 4, 1)\n",
      "Shape of x_test is  (12, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train is ', x_train.shape)\n",
    "print('Shape of x_test is ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jergb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importa el modelo secuencial, permite apilar capas de manera lineal\n",
    "from keras.models import Sequential\n",
    "# importa la capa densa, esta es una capa de red neuronal completamente conectada regular\n",
    "# con una función lineal de activación\n",
    "from keras.layers import Dense, Activation\n",
    "# Optimizador de descenso de gradiente estocástico\n",
    "from keras.optimizers import SGD\n",
    "# importa una red neuronal recurrente completamente conectada\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "\n",
    "# importa todas las capas\n",
    "#from keras.layers import *\n",
    "#from keras.layers.recurrent import LSTM\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una semilla para tener resultados repetibles\n",
    "seed = 2016\n",
    "np.random.seed(seed)\n",
    "# Define el modelo secuencial\n",
    "fit1 = Sequential()\n",
    "# Agrega una capa LSTM con cuatro neuronas, activación tanh, activación interoir hard_sgimoitde\n",
    "# y forma de entrada (5,1)\n",
    "fit1.add(SimpleRNN(units=8, activation='tanh',input_shape=(4, 1)))\n",
    "#Agrega una capa densa con una slida y activación lineal\n",
    "fit1.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿cómo se establece el valor óptimo de impulso? A menudo es útil experimentar con diferentes valores. Una regla de oro es reducir la velocidad de aprendizaje cuando se usa mucho impulso.\n",
    "Usando esta idea, seleccionamos una tasa de aprendizaje baja de 0.0001 combinada con un valor de impulso relativamente alto de 0.95:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we set nestrov = True to use Nesterov’s accelerated\n",
    "#This is a first-order optimization method designed to improve stability and speed up convergence of gradient descent.\n",
    "\n",
    "sgd = SGD(lr=0.0001, momentum=0.95, nesterov=True)\n",
    "fit1.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the batch size, the more memory you\n",
    "will need to run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.1802\n",
      "Epoch 2/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.1184\n",
      "Epoch 3/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0890\n",
      "Epoch 4/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0753\n",
      "Epoch 5/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0645\n",
      "Epoch 6/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0564\n",
      "Epoch 7/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0498\n",
      "Epoch 8/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0451\n",
      "Epoch 9/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0412\n",
      "Epoch 10/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0381\n",
      "Epoch 11/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0356\n",
      "Epoch 12/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0335\n",
      "Epoch 13/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0316\n",
      "Epoch 14/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0302\n",
      "Epoch 15/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0289\n",
      "Epoch 16/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0279\n",
      "Epoch 17/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0268\n",
      "Epoch 18/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0260\n",
      "Epoch 19/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0252\n",
      "Epoch 20/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0245\n",
      "Epoch 21/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0238\n",
      "Epoch 22/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0233\n",
      "Epoch 23/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0227\n",
      "Epoch 24/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0222\n",
      "Epoch 25/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0218\n",
      "Epoch 26/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0214\n",
      "Epoch 27/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0209\n",
      "Epoch 28/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0205\n",
      "Epoch 29/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0201\n",
      "Epoch 30/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0198\n",
      "Epoch 31/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0195\n",
      "Epoch 32/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0191\n",
      "Epoch 33/700\n",
      "250/250 [==============================] - 0s 204us/step - loss: 0.0188\n",
      "Epoch 34/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0185\n",
      "Epoch 35/700\n",
      "250/250 [==============================] - 0s 200us/step - loss: 0.0182\n",
      "Epoch 36/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0179\n",
      "Epoch 37/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0177\n",
      "Epoch 38/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0174\n",
      "Epoch 39/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0171\n",
      "Epoch 40/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0169\n",
      "Epoch 41/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0166\n",
      "Epoch 42/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0164\n",
      "Epoch 43/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0162\n",
      "Epoch 44/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0160\n",
      "Epoch 45/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0157\n",
      "Epoch 46/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0155\n",
      "Epoch 47/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0153\n",
      "Epoch 48/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0151\n",
      "Epoch 49/700\n",
      "250/250 [==============================] - 0s 200us/step - loss: 0.0149\n",
      "Epoch 50/700\n",
      "250/250 [==============================] - 0s 208us/step - loss: 0.0147\n",
      "Epoch 51/700\n",
      "250/250 [==============================] - 0s 208us/step - loss: 0.0145\n",
      "Epoch 52/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0143\n",
      "Epoch 53/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0142\n",
      "Epoch 54/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0140\n",
      "Epoch 55/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0138\n",
      "Epoch 56/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0137\n",
      "Epoch 57/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0135\n",
      "Epoch 58/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0133\n",
      "Epoch 59/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0132\n",
      "Epoch 60/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0130\n",
      "Epoch 61/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0129\n",
      "Epoch 62/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0127\n",
      "Epoch 63/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0126\n",
      "Epoch 64/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0125\n",
      "Epoch 65/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0123\n",
      "Epoch 66/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0122\n",
      "Epoch 67/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0121\n",
      "Epoch 68/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0120\n",
      "Epoch 69/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0119\n",
      "Epoch 70/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0117\n",
      "Epoch 71/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0116\n",
      "Epoch 72/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0115\n",
      "Epoch 73/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0114\n",
      "Epoch 74/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0113\n",
      "Epoch 75/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0112\n",
      "Epoch 76/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0111\n",
      "Epoch 77/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0110\n",
      "Epoch 78/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0109\n",
      "Epoch 79/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0108\n",
      "Epoch 80/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0107\n",
      "Epoch 81/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0106\n",
      "Epoch 82/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0105\n",
      "Epoch 83/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0104\n",
      "Epoch 84/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0103\n",
      "Epoch 85/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0103\n",
      "Epoch 86/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0102\n",
      "Epoch 87/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0101\n",
      "Epoch 88/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0100\n",
      "Epoch 89/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0099\n",
      "Epoch 90/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0098\n",
      "Epoch 91/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0098\n",
      "Epoch 92/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0097\n",
      "Epoch 93/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0096\n",
      "Epoch 94/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0096\n",
      "Epoch 95/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0095\n",
      "Epoch 96/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0094\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 156us/step - loss: 0.0094\n",
      "Epoch 98/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0093\n",
      "Epoch 99/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0092\n",
      "Epoch 100/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0092\n",
      "Epoch 101/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0091\n",
      "Epoch 102/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0090\n",
      "Epoch 103/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0090\n",
      "Epoch 104/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0089\n",
      "Epoch 105/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0089\n",
      "Epoch 106/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0088\n",
      "Epoch 107/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0088\n",
      "Epoch 108/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0087\n",
      "Epoch 109/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0087\n",
      "Epoch 110/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0086\n",
      "Epoch 111/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0086\n",
      "Epoch 112/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0085\n",
      "Epoch 113/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0084\n",
      "Epoch 114/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0084\n",
      "Epoch 115/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0083\n",
      "Epoch 116/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0083\n",
      "Epoch 117/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0083\n",
      "Epoch 118/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0082\n",
      "Epoch 119/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0082\n",
      "Epoch 120/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0081\n",
      "Epoch 121/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0081\n",
      "Epoch 122/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0080\n",
      "Epoch 123/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0080\n",
      "Epoch 124/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0080\n",
      "Epoch 125/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0079\n",
      "Epoch 126/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0079\n",
      "Epoch 127/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0078\n",
      "Epoch 128/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0078\n",
      "Epoch 129/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0078\n",
      "Epoch 130/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0077\n",
      "Epoch 131/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0077\n",
      "Epoch 132/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0077\n",
      "Epoch 133/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0076\n",
      "Epoch 134/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0076\n",
      "Epoch 135/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0075\n",
      "Epoch 136/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0075\n",
      "Epoch 137/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0075\n",
      "Epoch 138/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0074\n",
      "Epoch 139/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0074\n",
      "Epoch 140/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0074\n",
      "Epoch 141/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0073\n",
      "Epoch 142/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0073\n",
      "Epoch 143/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0073\n",
      "Epoch 144/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0073\n",
      "Epoch 145/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0072\n",
      "Epoch 146/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0072\n",
      "Epoch 147/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0072\n",
      "Epoch 148/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0071\n",
      "Epoch 149/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0071\n",
      "Epoch 150/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0071\n",
      "Epoch 151/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0071\n",
      "Epoch 152/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0070\n",
      "Epoch 153/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0070\n",
      "Epoch 154/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0070\n",
      "Epoch 155/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0070\n",
      "Epoch 156/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0069\n",
      "Epoch 157/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0069\n",
      "Epoch 158/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0069\n",
      "Epoch 159/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0068\n",
      "Epoch 160/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0068\n",
      "Epoch 161/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0068\n",
      "Epoch 162/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0068\n",
      "Epoch 163/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0068\n",
      "Epoch 164/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0067\n",
      "Epoch 165/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0067\n",
      "Epoch 166/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0067\n",
      "Epoch 167/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0067\n",
      "Epoch 168/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0066\n",
      "Epoch 169/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0066\n",
      "Epoch 170/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0066\n",
      "Epoch 171/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0066\n",
      "Epoch 172/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0065\n",
      "Epoch 173/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0065\n",
      "Epoch 174/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0065\n",
      "Epoch 175/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0065\n",
      "Epoch 176/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0065\n",
      "Epoch 177/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0065\n",
      "Epoch 178/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0064\n",
      "Epoch 179/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0064\n",
      "Epoch 180/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0064\n",
      "Epoch 181/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0064\n",
      "Epoch 182/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0063\n",
      "Epoch 183/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0063\n",
      "Epoch 184/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0063\n",
      "Epoch 185/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0063\n",
      "Epoch 186/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0063\n",
      "Epoch 187/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0063\n",
      "Epoch 188/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0062\n",
      "Epoch 189/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0062\n",
      "Epoch 190/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0062\n",
      "Epoch 191/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0062\n",
      "Epoch 192/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 128us/step - loss: 0.0062\n",
      "Epoch 193/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0062\n",
      "Epoch 194/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0061\n",
      "Epoch 195/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0061\n",
      "Epoch 196/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0061\n",
      "Epoch 197/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0061\n",
      "Epoch 198/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0061\n",
      "Epoch 199/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0061\n",
      "Epoch 200/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0060\n",
      "Epoch 201/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0060\n",
      "Epoch 202/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0060\n",
      "Epoch 203/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0060\n",
      "Epoch 204/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0060\n",
      "Epoch 205/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0060\n",
      "Epoch 206/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0060\n",
      "Epoch 207/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0059\n",
      "Epoch 208/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0059\n",
      "Epoch 209/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0059\n",
      "Epoch 210/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0059\n",
      "Epoch 211/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0059\n",
      "Epoch 212/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0059\n",
      "Epoch 213/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0058\n",
      "Epoch 214/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0058\n",
      "Epoch 215/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0058\n",
      "Epoch 216/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0058\n",
      "Epoch 217/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0058\n",
      "Epoch 218/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0058\n",
      "Epoch 219/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0058\n",
      "Epoch 220/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0057\n",
      "Epoch 221/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0057\n",
      "Epoch 222/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0057\n",
      "Epoch 223/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0057\n",
      "Epoch 224/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0057\n",
      "Epoch 225/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0057\n",
      "Epoch 226/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0057\n",
      "Epoch 227/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0057\n",
      "Epoch 228/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0056\n",
      "Epoch 229/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0056\n",
      "Epoch 230/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0056\n",
      "Epoch 231/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0056\n",
      "Epoch 232/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0056\n",
      "Epoch 233/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0056\n",
      "Epoch 234/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0056\n",
      "Epoch 235/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0056\n",
      "Epoch 236/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0055\n",
      "Epoch 237/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0055\n",
      "Epoch 238/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0055\n",
      "Epoch 239/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0055\n",
      "Epoch 240/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0055\n",
      "Epoch 241/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0055\n",
      "Epoch 242/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0055\n",
      "Epoch 243/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0055\n",
      "Epoch 244/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0055\n",
      "Epoch 245/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0055\n",
      "Epoch 246/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0054\n",
      "Epoch 247/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0054\n",
      "Epoch 248/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0054\n",
      "Epoch 249/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0054\n",
      "Epoch 250/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0054\n",
      "Epoch 251/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0054\n",
      "Epoch 252/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0054\n",
      "Epoch 253/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0054\n",
      "Epoch 254/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0054\n",
      "Epoch 255/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0053\n",
      "Epoch 256/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0053\n",
      "Epoch 257/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0053\n",
      "Epoch 258/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0053\n",
      "Epoch 259/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0053\n",
      "Epoch 260/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0053\n",
      "Epoch 261/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0053\n",
      "Epoch 262/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0053\n",
      "Epoch 263/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0053\n",
      "Epoch 264/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0053\n",
      "Epoch 265/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0052\n",
      "Epoch 266/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0052\n",
      "Epoch 267/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0052\n",
      "Epoch 268/700\n",
      "250/250 [==============================] - 0s 208us/step - loss: 0.0052\n",
      "Epoch 269/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0052\n",
      "Epoch 270/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0052\n",
      "Epoch 271/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0052\n",
      "Epoch 272/700\n",
      "250/250 [==============================] - 0s 216us/step - loss: 0.0052\n",
      "Epoch 273/700\n",
      "250/250 [==============================] - 0s 200us/step - loss: 0.0052\n",
      "Epoch 274/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0052\n",
      "Epoch 275/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0052\n",
      "Epoch 276/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0052\n",
      "Epoch 277/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0051\n",
      "Epoch 278/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0051\n",
      "Epoch 279/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0051\n",
      "Epoch 280/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0051\n",
      "Epoch 281/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0051\n",
      "Epoch 282/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0051\n",
      "Epoch 283/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0051\n",
      "Epoch 284/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0051\n",
      "Epoch 285/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0051\n",
      "Epoch 286/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0051\n",
      "Epoch 287/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 128us/step - loss: 0.0051\n",
      "Epoch 288/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0051\n",
      "Epoch 289/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0051\n",
      "Epoch 290/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0050\n",
      "Epoch 291/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0050\n",
      "Epoch 292/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0050\n",
      "Epoch 293/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0050\n",
      "Epoch 294/700\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0050\n",
      "Epoch 295/700\n",
      "250/250 [==============================] - 0s 200us/step - loss: 0.0050\n",
      "Epoch 296/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0050\n",
      "Epoch 297/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0050\n",
      "Epoch 298/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0050\n",
      "Epoch 299/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0050\n",
      "Epoch 300/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0050\n",
      "Epoch 301/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0050\n",
      "Epoch 302/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0049\n",
      "Epoch 303/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0050\n",
      "Epoch 304/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0049\n",
      "Epoch 305/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0049\n",
      "Epoch 306/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0049\n",
      "Epoch 307/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0049\n",
      "Epoch 308/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0049\n",
      "Epoch 309/700\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.0049\n",
      "Epoch 310/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0049\n",
      "Epoch 311/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0049\n",
      "Epoch 312/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0049\n",
      "Epoch 313/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0049\n",
      "Epoch 314/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0049\n",
      "Epoch 315/700\n",
      "250/250 [==============================] - 0s 192us/step - loss: 0.0049\n",
      "Epoch 316/700\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0049\n",
      "Epoch 317/700\n",
      "250/250 [==============================] - 0s 204us/step - loss: 0.0048\n",
      "Epoch 318/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0048\n",
      "Epoch 319/700\n",
      "250/250 [==============================] - 0s 212us/step - loss: 0.0048\n",
      "Epoch 320/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0048\n",
      "Epoch 321/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0048\n",
      "Epoch 322/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0048\n",
      "Epoch 323/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0048\n",
      "Epoch 324/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0048\n",
      "Epoch 325/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0048\n",
      "Epoch 326/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0048\n",
      "Epoch 327/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0048\n",
      "Epoch 328/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0048\n",
      "Epoch 329/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0048\n",
      "Epoch 330/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0048\n",
      "Epoch 331/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0048\n",
      "Epoch 332/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0048\n",
      "Epoch 333/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0047\n",
      "Epoch 334/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0047\n",
      "Epoch 335/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0047\n",
      "Epoch 336/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0047\n",
      "Epoch 337/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0047\n",
      "Epoch 338/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0047\n",
      "Epoch 339/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0047\n",
      "Epoch 340/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0047\n",
      "Epoch 341/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0047\n",
      "Epoch 342/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0047\n",
      "Epoch 343/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0047\n",
      "Epoch 344/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0047\n",
      "Epoch 345/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0047\n",
      "Epoch 346/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0047\n",
      "Epoch 347/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0047\n",
      "Epoch 348/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0047\n",
      "Epoch 349/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0047\n",
      "Epoch 350/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0046\n",
      "Epoch 351/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0046\n",
      "Epoch 352/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0046\n",
      "Epoch 353/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0046\n",
      "Epoch 354/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0046\n",
      "Epoch 355/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0046\n",
      "Epoch 356/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0046\n",
      "Epoch 357/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0046\n",
      "Epoch 358/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0046\n",
      "Epoch 359/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0046\n",
      "Epoch 360/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0046\n",
      "Epoch 361/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0046\n",
      "Epoch 362/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0046\n",
      "Epoch 363/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0046\n",
      "Epoch 364/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0046\n",
      "Epoch 365/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0046\n",
      "Epoch 366/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0046\n",
      "Epoch 367/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0046\n",
      "Epoch 368/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0046\n",
      "Epoch 369/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 370/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 371/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0045\n",
      "Epoch 372/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 373/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0045\n",
      "Epoch 374/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0045\n",
      "Epoch 375/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0045\n",
      "Epoch 376/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0045\n",
      "Epoch 377/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0045\n",
      "Epoch 378/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0045\n",
      "Epoch 379/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0045\n",
      "Epoch 380/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0045\n",
      "Epoch 381/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0045\n",
      "Epoch 382/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 140us/step - loss: 0.0045\n",
      "Epoch 383/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 384/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0045\n",
      "Epoch 385/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 386/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 387/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0045\n",
      "Epoch 388/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 389/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0045\n",
      "Epoch 390/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0045\n",
      "Epoch 391/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 392/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 393/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0044\n",
      "Epoch 394/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0044\n",
      "Epoch 395/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0044\n",
      "Epoch 396/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0044\n",
      "Epoch 397/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 398/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0044\n",
      "Epoch 399/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0044\n",
      "Epoch 400/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0044\n",
      "Epoch 401/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0044\n",
      "Epoch 402/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0044\n",
      "Epoch 403/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 404/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0044\n",
      "Epoch 405/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0044\n",
      "Epoch 406/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 407/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0044\n",
      "Epoch 408/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0044\n",
      "Epoch 409/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0044\n",
      "Epoch 410/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0044\n",
      "Epoch 411/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0044\n",
      "Epoch 412/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0044\n",
      "Epoch 413/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0044\n",
      "Epoch 414/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0044\n",
      "Epoch 415/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0044\n",
      "Epoch 416/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0043\n",
      "Epoch 417/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0044\n",
      "Epoch 418/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0043\n",
      "Epoch 419/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0043\n",
      "Epoch 420/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0043\n",
      "Epoch 421/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0043\n",
      "Epoch 422/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0043\n",
      "Epoch 423/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0043\n",
      "Epoch 424/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0043\n",
      "Epoch 425/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0043\n",
      "Epoch 426/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0043\n",
      "Epoch 427/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0043\n",
      "Epoch 428/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0043\n",
      "Epoch 429/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0043\n",
      "Epoch 430/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0043\n",
      "Epoch 431/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0043\n",
      "Epoch 432/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0043\n",
      "Epoch 433/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0043\n",
      "Epoch 434/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0043\n",
      "Epoch 435/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0043\n",
      "Epoch 436/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0043\n",
      "Epoch 437/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0043\n",
      "Epoch 438/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0043\n",
      "Epoch 439/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0043\n",
      "Epoch 440/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0043\n",
      "Epoch 441/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0043\n",
      "Epoch 442/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0042\n",
      "Epoch 443/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0042\n",
      "Epoch 444/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042\n",
      "Epoch 445/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 446/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 447/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042\n",
      "Epoch 448/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042\n",
      "Epoch 449/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 450/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0042\n",
      "Epoch 451/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0042\n",
      "Epoch 452/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0042\n",
      "Epoch 453/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0042\n",
      "Epoch 454/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0042\n",
      "Epoch 455/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0042\n",
      "Epoch 456/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 457/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042\n",
      "Epoch 458/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 459/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0042\n",
      "Epoch 460/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0042\n",
      "Epoch 461/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042\n",
      "Epoch 462/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0042\n",
      "Epoch 463/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0042\n",
      "Epoch 464/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0042\n",
      "Epoch 465/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0042\n",
      "Epoch 466/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0042\n",
      "Epoch 467/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0042\n",
      "Epoch 468/700\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0042\n",
      "Epoch 469/700\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0042\n",
      "Epoch 470/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 471/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 472/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0042\n",
      "Epoch 473/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0042\n",
      "Epoch 474/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0042\n",
      "Epoch 475/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0041\n",
      "Epoch 476/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0041\n",
      "Epoch 477/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 140us/step - loss: 0.0041\n",
      "Epoch 478/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0041\n",
      "Epoch 479/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 480/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041\n",
      "Epoch 481/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 482/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0041\n",
      "Epoch 483/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0041\n",
      "Epoch 484/700\n",
      "250/250 [==============================] - 0s 204us/step - loss: 0.0041\n",
      "Epoch 485/700\n",
      "250/250 [==============================] - 0s 240us/step - loss: 0.0041\n",
      "Epoch 486/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0041\n",
      "Epoch 487/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0041\n",
      "Epoch 488/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0041\n",
      "Epoch 489/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0041\n",
      "Epoch 490/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0041\n",
      "Epoch 491/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0041\n",
      "Epoch 492/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041\n",
      "Epoch 493/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0041\n",
      "Epoch 494/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0041\n",
      "Epoch 495/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 496/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0041\n",
      "Epoch 497/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0041\n",
      "Epoch 498/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 499/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0041\n",
      "Epoch 500/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0041\n",
      "Epoch 501/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0041\n",
      "Epoch 502/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041\n",
      "Epoch 503/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041\n",
      "Epoch 504/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0041\n",
      "Epoch 505/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0041\n",
      "Epoch 506/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0041\n",
      "Epoch 507/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0041\n",
      "Epoch 508/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 509/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 510/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0040\n",
      "Epoch 511/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0040\n",
      "Epoch 512/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0041\n",
      "Epoch 513/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 514/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 515/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0040\n",
      "Epoch 516/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0040\n",
      "Epoch 517/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 518/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 519/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 520/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 521/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0040\n",
      "Epoch 522/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0040\n",
      "Epoch 523/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 524/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0040\n",
      "Epoch 525/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 526/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 527/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 528/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 529/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 530/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 531/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0040\n",
      "Epoch 532/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 533/700\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0040\n",
      "Epoch 534/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0040\n",
      "Epoch 535/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0040\n",
      "Epoch 536/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 537/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 538/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 539/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0040\n",
      "Epoch 540/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0040\n",
      "Epoch 541/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0040\n",
      "Epoch 542/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0040\n",
      "Epoch 543/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0040\n",
      "Epoch 544/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040\n",
      "Epoch 545/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0040\n",
      "Epoch 546/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0040\n",
      "Epoch 547/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0040\n",
      "Epoch 548/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 549/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0040\n",
      "Epoch 550/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0040\n",
      "Epoch 551/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0040\n",
      "Epoch 552/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0040\n",
      "Epoch 553/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0039\n",
      "Epoch 554/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 555/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0039\n",
      "Epoch 556/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0039\n",
      "Epoch 557/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 558/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0039\n",
      "Epoch 559/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 560/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 561/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0039\n",
      "Epoch 562/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 563/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0039\n",
      "Epoch 564/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0039\n",
      "Epoch 565/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0039\n",
      "Epoch 566/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0039\n",
      "Epoch 567/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0039\n",
      "Epoch 568/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 569/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 570/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 571/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0039\n",
      "Epoch 572/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 573/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0039\n",
      "Epoch 574/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0039\n",
      "Epoch 575/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 576/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 577/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0039\n",
      "Epoch 578/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0039\n",
      "Epoch 579/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 580/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0039\n",
      "Epoch 581/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0039\n",
      "Epoch 582/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0039\n",
      "Epoch 583/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0039\n",
      "Epoch 584/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 585/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0039\n",
      "Epoch 586/700\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0039\n",
      "Epoch 587/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0039\n",
      "Epoch 588/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 589/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0039\n",
      "Epoch 590/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0039\n",
      "Epoch 591/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 592/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 593/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 594/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 595/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 596/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 597/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 598/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 599/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0039\n",
      "Epoch 600/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0039\n",
      "Epoch 601/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0039\n",
      "Epoch 602/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 603/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0039\n",
      "Epoch 604/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 605/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 606/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0038\n",
      "Epoch 607/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 608/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 609/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 610/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0038\n",
      "Epoch 611/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0038\n",
      "Epoch 612/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0038\n",
      "Epoch 613/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 614/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0038\n",
      "Epoch 615/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0038\n",
      "Epoch 616/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0038\n",
      "Epoch 617/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0038\n",
      "Epoch 618/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 619/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 620/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0038\n",
      "Epoch 621/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 622/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0038\n",
      "Epoch 623/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 624/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 625/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 626/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 627/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0038\n",
      "Epoch 628/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 629/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0038\n",
      "Epoch 630/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 631/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0038\n",
      "Epoch 632/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 633/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 634/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0038\n",
      "Epoch 635/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0038\n",
      "Epoch 636/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 637/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0038\n",
      "Epoch 638/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0038\n",
      "Epoch 639/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0038\n",
      "Epoch 640/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 641/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0038\n",
      "Epoch 642/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 643/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 644/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 645/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0038\n",
      "Epoch 646/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0038\n",
      "Epoch 647/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0038\n",
      "Epoch 648/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0038\n",
      "Epoch 649/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0038\n",
      "Epoch 650/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 651/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0038\n",
      "Epoch 652/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0038\n",
      "Epoch 653/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0038\n",
      "Epoch 654/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0038\n",
      "Epoch 655/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0038\n",
      "Epoch 656/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 657/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0038\n",
      "Epoch 658/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0038\n",
      "Epoch 659/700\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.0038\n",
      "Epoch 660/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0037\n",
      "Epoch 661/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 662/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0037\n",
      "Epoch 663/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0037\n",
      "Epoch 664/700\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0037\n",
      "Epoch 665/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0037\n",
      "Epoch 666/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0037\n",
      "Epoch 667/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 132us/step - loss: 0.0037\n",
      "Epoch 668/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0037\n",
      "Epoch 669/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 670/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0037\n",
      "Epoch 671/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 672/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 673/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 674/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0037\n",
      "Epoch 675/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0037\n",
      "Epoch 676/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 677/700\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0037\n",
      "Epoch 678/700\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0037\n",
      "Epoch 679/700\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0037\n",
      "Epoch 680/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0037\n",
      "Epoch 681/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 682/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0037\n",
      "Epoch 683/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 684/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 685/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0037\n",
      "Epoch 686/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0037\n",
      "Epoch 687/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 688/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 689/700\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0037\n",
      "Epoch 690/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 691/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 692/700\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.0037\n",
      "Epoch 693/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0037\n",
      "Epoch 694/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0037\n",
      "Epoch 695/700\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0037\n",
      "Epoch 696/700\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0037\n",
      "Epoch 697/700\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0037\n",
      "Epoch 698/700\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0037\n",
      "Epoch 699/700\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.0037\n",
      "Epoch 700/700\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d58679198>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit1.fit(x_train, y_train, batch_size=10, nb_epoch=700)\n",
    "fit1.fit(x_train, y_train, batch_size=10, epochs=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 320us/step\n",
      "12/12 [==============================] - 0s 250us/step\n"
     ]
    }
   ],
   "source": [
    "score_train = fit1.evaluate(x_train, y_train, batch_size=10)\n",
    "score_test = fit1.evaluate(x_test, y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in train MSE =  0.003688\n",
      "in test MSE =  0.004232\n"
     ]
    }
   ],
   "source": [
    "print('in train MSE = ', round(score_train,6))\n",
    "print('in test MSE = ', round( score_test ,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in train MSE =  0.003688  \n",
    "in test MSE =  0.004232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to convert the predictions back to their original scale,\n",
    "so we can view them individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12518.],\n",
       "       [12262.],\n",
       "       [12411.],\n",
       "       [12351.],\n",
       "       [12892.],\n",
       "       [12959.],\n",
       "       [12931.],\n",
       "       [12375.],\n",
       "       [12440.],\n",
       "       [12476.],\n",
       "       [12496.],\n",
       "       [12532.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10803.],\n",
       "       [11101.],\n",
       "       [12699.],\n",
       "       [13605.],\n",
       "       [15200.],\n",
       "       [14900.],\n",
       "       [13000.],\n",
       "       [12605.],\n",
       "       [14156.],\n",
       "       [14501.],\n",
       "       [14669.],\n",
       "       [13499.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred1 = fit1.predict(x_test)\n",
    "pred1 = scaler_y.inverse_transform(np.array(pred1).reshape((len(pred1),1)))\n",
    "pred1 = np.exp(pred1)\n",
    "display(np.rint(pred1))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.rint(pred1))\n",
    "\n",
    "entreno = scaler_y.inverse_transform(np.array(y_test).reshape((len(y_test),1)))\n",
    "entreno = np.exp(entreno)\n",
    "display(np.rint(entreno))\n",
    "plt.plot(np.rint(entreno))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0026\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d58d25588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compila el model con función de pérdidas MSE y optimizador rmsprop\n",
    "# EL optimiador rmsprop actualiza el ritmo de aprendizaje del gradiente descendiente\n",
    "fit1.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "#Ajustar el modelo\n",
    "fit1.fit(x_train, y_train, batch_size = 1, epochs=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamo a revisar qué tan bueno es el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-cdc18161fd4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgru\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'GRU' is not defined"
     ]
    }
   ],
   "source": [
    "gru = GRU(50)(Input(shape = (10, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gru.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(50, return_sequences = False, return_state = True)(Input(shape = (10, 30)))\n",
    "print(gru[0].shape)         # shape of output\n",
    "print(gru[1].shape)         # shape of hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(50, return_sequences = True, return_state = True)(Input(shape = (10, 30)))\n",
    "print(gru[0].shape)         # shape of output\n",
    "print(gru[1].shape)         # shape of hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden_state = GRU(50, return_sequences = True, return_state = True)(Input(shape = (10, 30)))\n",
    "print(output.shape)\n",
    "print(hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una semilla para tener resultados repetibles\n",
    "seed = 2016\n",
    "np.random.seed(seed)\n",
    "# Define el modelo secuencial\n",
    "fit1 = Sequential()\n",
    "# Agrega una capa LSTM con cuatro neuronas, activación tanh, activación interoir hard_sgimoitde\n",
    "# y forma de entrada (5,1)\n",
    "fit1.add(LSTM(output_dim=4, activation='tanh', inner_activation='hard_sigmoid',input_shape=(5, 1)))\n",
    "#Agrega una capa densa con una slida y activación lineal\n",
    "fit1.add(Dense(output_dim=1, activation='linear'))\n",
    "#Compila el model con función de pérdidas MSE y optimizador rmsprop\n",
    "# EL optimiador rmsprop actualiza el ritmo de aprendizaje del gradiente descendiente\n",
    "fit1.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "#Ajustar el modelo\n",
    "fit1.fit(x_train, y_train, batch_size = 1, nb_epoch=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
